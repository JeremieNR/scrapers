# -*- coding: utf-8 -*-
"""SFChron scrape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17C3__0RZQPx8_c-sOtauu8cvjEVHQLSO
"""

import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime as dt

response = requests.get('https://www.sfchronicle.com')
lines_split = "".join(line.strip() for line in response.text.split('\n'))
doc = BeautifulSoup(lines_split, 'html.parser')

headlines = doc('a', class_='hdn-analytics')

formatted = []
for headline in headlines:
  if 'visit|article' in headline['data-hdn-analytics'] or 'visit|blogPost' in headline['data-hdn-analytics']:
    type = headline['data-hdn-analytics'].split('|')[1].split('-')[0]
    link = f'https://www.sfchronicle.com{headline["href"]}' if type == 'article' else headline['href']
    section = link.split('/')[3]
    formatted.append({
        'headline': headline.text.strip(),
        'type': type,
        'section': section,
        'link': link,
    })

contents = {
    'date_scraped': dt.now().strftime("%Y-%m-%d-%H:%M:%S"),
    'data': formatted
  }

with open('headlines/sfchron/sfchron.json', 'w') as file:
  json.dump(contents, file)